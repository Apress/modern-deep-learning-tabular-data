{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"dl4td-chapter-8.ipynb","provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# *Modern Deep Learning for Tabular Data*, Chapter 8\n","\n","**Autoencoders**\n","\n","This notebook contains the complementary code discussed in Chapter 8 of *Modern Deep Learning for Tabular Data*.\n","\n","External Kaggle links to datasets used in this notebook:\n","- [Mouse Protein Expression Dataset](https://www.kaggle.com/datasets/washingtongold/mpempe)\n","- [Higgs Boson Dataset](https://www.kaggle.com/datasets/mragpavank/higs-bonsons-and-background-process)\n","\n","You can download these datasets from Kaggle, or import these notebooks into Kaggle and connect them internally."],"metadata":{"id":"IeZN3CLIK2Ml"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"jPOLz-34K2Mn"}},{"cell_type":"markdown","source":["## Importing and Installing Libraries"],"metadata":{"id":"LKFo1JuTK2Mn"}},{"cell_type":"code","source":["# data management\n","import numpy as np                   # for linear algebra\n","import pandas as pd                  # for tabular data manipulation and processing\n","\n","# machine learning\n","import sklearn                       # for data prep and classical ML\n","import tensorflow as tf              # for deep learning\n","from tensorflow import keras         # for deep learning\n","import keras.layers as L             # for easy NN layer access\n","\n","# data visualization and graphics\n","import matplotlib.pyplot as plt      # for visualization fundamentals\n","import seaborn as sns                # for pretty visualizations\n","import cv2                           # for image manipulation\n","\n","# misc\n","from tqdm.notebook import tqdm       # for progress bars\n","import math                          # for calculation\n","import sys                           # for system manipulation\n","import os                            # for file manipulation"],"metadata":{"id":"z8vJDOWAK2Mn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"k_4ORmAfK2Mo"}},{"cell_type":"markdown","source":["## Vanilla Autoencoders"],"metadata":{"id":"mmarfH5DK2Mo"}},{"cell_type":"markdown","source":["Let's begin by loading MNIST data."],"metadata":{"id":"SY433DYHX48T"}},{"cell_type":"code","source":["(x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(len(x_train),784)/255\n","x_valid = x_valid.reshape(len(x_valid),784)/255"],"metadata":{"id":"I2pBR1fRK2Mp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating an autoencoder on MNIST."],"metadata":{"id":"hgcUNRT6X7QM"}},{"cell_type":"code","source":["from keras.models import Sequential\n","\n","# define architecture\n","model = Sequential()\n","model.add(L.Input((784,)))\n","model.add(L.Dense(256, activation='relu'))\n","model.add(L.Dense(64, activation='relu'))\n","model.add(L.Dense(32, activation='relu'))\n","model.add(L.Dense(64, activation='relu'))\n","model.add(L.Dense(256, activation='relu'))\n","model.add(L.Dense(784, activation='sigmoid'))\n","\n","# compile\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy')\n","\n","# fit\n","model.fit(x_train, x_train, epochs=1,\n","          validation_data=(x_valid, x_valid))"],"metadata":{"id":"INxBJR78K2Mp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using compartmentalized submodel design."],"metadata":{"id":"N7_-29DxX_RL"}},{"cell_type":"code","source":["from keras.models import Model\n","\n","# define architecture components\n","encoder = Sequential(name='encoder')\n","encoder.add(L.Input((784,)))\n","encoder.add(L.Dense(256, activation='relu'))\n","encoder.add(L.Dense(64, activation='relu'))\n","encoder.add(L.Dense(32, activation='relu')) \n","\n","decoder = Sequential(name='decoder')\n","decoder.add(L.Input((32,)))\n","decoder.add(L.Dense(64, activation='relu'))\n","decoder.add(L.Dense(256, activation='relu'))\n","decoder.add(L.Dense(784, activation='sigmoid'))\n","\n","# define model architecture from components\n","ae_input = L.Input((784,), name='input')\n","ae_encoder = encoder(ae_input)\n","ae_decoder = decoder(ae_encoder)\n","ae = Model(inputs = ae_input,\n","           outputs = ae_decoder)\n","\n","# compile\n","ae.compile(optimizer='adam',\n","           loss='binary_crossentropy') # note that in other situations other losses may be more suitable\n","\n","# fit\n","history = ae.fit(x_train, x_train, epochs=1,\n","                 validation_data=(x_valid, x_valid))"],"metadata":{"id":"TUUMz6m6K2Mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensorflow.keras.utils.plot_model(ae, show_shapes=True, dpi=400)"],"metadata":{"id":"G16evw1VK2Mq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Demonstrating the latent space compressions of the autoencoder."],"metadata":{"id":"bQKrvKAiYDtC"}},{"cell_type":"code","source":["plt.set_cmap('gray')\n","for i in range(10):\n","    plt.figure(figsize=(10, 5), dpi=400)\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(x_valid[i].reshape((28, 28)))\n","    plt.axis('off')\n","    plt.title('Original Input')\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(encoder.predict(x_valid[i:i+1]).reshape((8, 4)))\n","    plt.axis('off')\n","    plt.title('Latent Space (Reshaped)')\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(ae.predict(x_valid[i:i+1]).reshape((28, 28)))\n","    plt.axis('off')\n","    plt.title('Reconstructed')\n","    plt.show()"],"metadata":{"id":"Rl9jfvUBK2Mq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A generic autoencoder creation function."],"metadata":{"id":"G5FTu6VFYLcE"}},{"cell_type":"code","source":["def buildAutoencoder(inputSize=784, latentSize=32, outActivation='sigmoid'):\n","\n","    # define architecture components\n","    encoder = Sequential(name='encoder')\n","    encoder.add(L.Input((inputSize,)))\n","    for i in range(int(np.floor(np.log2(inputSize/latentSize))), -1, -1):\n","        encoder.add(L.Dense(latentSize * 2**i, activation='relu'))\n","\n","    decoder = Sequential(name='decoder')\n","    decoder.add(L.Input((latentSize,)))\n","    for i in range(1,int(np.floor(np.log2(inputSize/latentSize)))+1):\n","        decoder.add(L.Dense(latentSize * 2**i, activation='relu'))\n","    decoder.add(L.Dense(inputSize, activation=outActivation))\n","\n","    # define model archtitecture from components\n","    ae_input = L.Input((inputSize,), name='input')\n","    ae_encoder = encoder(ae_input)\n","    ae_decoder = decoder(ae_encoder)\n","    ae = Model(inputs = ae_input,\n","               outputs = ae_decoder)\n","\n","    return {'model': ae, 'encoder': encoder, 'decoder': decoder}"],"metadata":{"id":"tihXuf3cK2Mq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["built_ae = buildAutoencoder(784, 32)['model']\n","tensorflow.keras.utils.plot_model(built_ae, show_shapes=True, dpi=400)"],"metadata":{"id":"ESser2PKK2Mr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Varying autoencoder performance by latent space size."],"metadata":{"id":"9p6UjTsuYPUS"}},{"cell_type":"code","source":["inputSize = 784\n","\n","earlyStopping = keras.callbacks.EarlyStopping(monitor='loss',\n","                                              patience=5)\n","\n","latentSizes = list(range(1, int(np.floor(np.log2(inputSize)))))\n","validPerf = []\n","trainHist = []\n","for latentSize in tqdm(latentSizes):\n","    model = buildAutoencoder(inputSize, 2**latentSize)['model']\n","    model.compile(optimizer='adam', loss='categorical_crossentropy')\n","    history = model.fit(x_train, x_train, epochs=50, callbacks=[earlyStopping], verbose=0)\n","    score = keras.metrics.MeanAbsoluteError()\n","    score.update_state(model.predict(x_valid), x_valid)\n","    validPerf.append(score.result().numpy())\n","    trainHist.append(history.history['loss'])\n","\n","plt.figure(figsize=(15, 7.5), dpi=400)\n","plt.plot(latentSizes, validPerf, color='red')\n","plt.ylabel('Validation Performance')\n","plt.xlabel('Latent Size (power of 2)')\n","plt.grid()\n","plt.show()\n","\n","plt.set_cmap('magma')\n","plt.figure(figsize=(20, 10), dpi=400)\n","for size, hist in zip(latentSizes, trainHist):\n","    plt.plot(hist, label=f'Latent Size {size}')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Performance')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"metadata":{"id":"KP0rkkkhK2Mr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizing the latent space of an overcomplete model."],"metadata":{"id":"20Flyv6KYVPy"}},{"cell_type":"code","source":["# sample overcomplete model - try visualizing the latent space!\n","\n","# model = Sequential()\n","# model.add(L.Input((784,)))\n","# model.add(L.Dense(1024, activation='relu'))\n","# model.add(L.Dense(2048, activation='relu'))\n","# model.add(L.Dense(1024, activation='relu'))\n","# model.add(L.Dense(784, activation='sigmoid'))\n","\n","# model.compile(optimizer='adam', loss='binary_crossentropy')\n","# model.fit(x_train, x_train, epochs=50)\n","\n","# from sklearn.manifold import TSNE\n","modelSet = buildAutoencoder(512, 512)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","model.compile(optimizer='adam', loss='binary_crossentropy')\n","model.fit(x_train, x_train, epochs=50, callbacks=[earlyStopping], verbose=0)\n","transformed = encoder.predict(x_train)\n","tsne_ = TSNE(n_components=2).fit_transform(transformed)\n","\n","plt.figure(figsize=(10, 10), dpi=400)\n","plt.scatter(tsne_[:,0], tsne_[:,1], c=y_train)\n","plt.show()\n","plt.close()"],"metadata":{"id":"8Kl724lDK2Mr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example line reconstruction task."],"metadata":{"id":"q2nEbs6zK2Mr"}},{"cell_type":"code","source":["x = np.zeros((1024, 50, 50))\n","for i in range(1024):\n","    start = [np.random.randint(0, 50), np.random.randint(0, 50)]\n","    end = [np.random.randint(0, 50), np.random.randint(0, 50)]\n","    x[i,:,:] = cv2.line(x[i,:,:], start, end, 1, 4)\n","x = x.reshape((1024, 50 * 50))\n","modelSet = buildAutoencoder(50 * 50, 4)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","model.compile(optimizer='adam', loss='binary_crossentropy')\n","model.fit(x, x, epochs=1, validation_split=0.2)\n","plt.set_cmap('gray')\n","for i in range(5):\n","    pred = model.predict(x[i:i+1]).reshape((50, 50))\n","    plt.figure(figsize=(10, 5), dpi=400)\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(x[i].reshape((50, 50)))\n","    plt.axis('off')\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(pred)\n","    plt.axis('off')\n","    plt.show()\n","    plt.close()"],"metadata":{"id":"oIkEtT3-K2Ms"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using an autoencoder on a real tabular dataset (Mouse Protein Expression dataset)."],"metadata":{"id":"x0UgYy_RK2Ms"}},{"cell_type":"code","source":["data = pd.read_csv('../input/mpempe/mouse-protein-expression.csv').drop('Unnamed: 0', axis=1)\n","x = data.drop('class', axis=1)\n","y = data['class']\n","modelSet = buildAutoencoder(len(x.columns), 8, outActivation='linear')\n","ae = modelSet['model']\n","encoder = modelSet['encoder']\n","\n","ae.compile(optimizer='adam',\n","           loss='mse',\n","           metrics=['mae'])\n","history = ae.fit(x, x, epochs=50)\n","plt.figure(figsize=(15, 7.5), dpi=400)\n","plt.plot(history.history['loss'], color='red')\n","plt.grid()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()\n","plt.close()"],"metadata":{"id":"Bfl_2dpdK2Ms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded = encoder.predict(x)\n","recon = ae.predict(x)\n","\n","plt.set_cmap('gray')\n","\n","for i in range(1):\n","    \n","    plt.figure(figsize=(10, 8), dpi=400)\n","    sns.heatmap(np.array(x.iloc[i]).reshape((8, 10)), cbar=False,\n","                xticklabels=[], yticklabels=[],\n","                cmap='gray',\n","                annot=True)\n","    plt.title('Input Features')\n","    plt.show()\n","    plt.close()\n","    \n","    plt.figure(figsize=(10, 8), dpi=400)\n","    sns.heatmap(np.array(recon[i]).reshape((8, 10)), cbar=False,\n","                xticklabels=[], yticklabels=[],\n","                cmap='gray',\n","                annot=True)\n","    plt.title('Reconstruction')\n","    plt.show()\n","    plt.close()\n","    \n","    plt.figure(figsize=(8, 1), dpi=400)\n","    sns.heatmap(encoded[i].reshape((1, 8)), cbar=False,\n","                xticklabels=[], yticklabels=[],\n","                cmap='gray')\n","    plt.title('Latent Space')\n","    plt.show()\n","    plt.close()\n","    \n","    print('-'*50)\n","\n","from sklearn.manifold import TSNE\n","transformed = encoder.predict(x)\n","tsne_ = TSNE(n_components=2).fit_transform(transformed)\n","\n","plt.figure(figsize=(10, 10), dpi=400)\n","plt.scatter(tsne_[:,0], tsne_[:,1], c=y, cmap='viridis')\n","plt.show()\n","plt.close()"],"metadata":{"id":"r8Cwnu3tK2Mt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying various latent space sizes to the Mouse Protein Expression dataset."],"metadata":{"id":"QdRGtTyUYxtR"}},{"cell_type":"code","source":["from sklearn.manifold import TSNE\n","\n","inputSize = len(x.columns)\n","\n","earlyStopping = keras.callbacks.EarlyStopping(monitor='loss',\n","                                              patience=5)\n","\n","latentSizes = list(range(1, int(np.floor(np.log2(inputSize)))))\n","\n","plt.set_cmap('viridis')\n","\n","for latentSize in tqdm(latentSizes):\n","    \n","    modelSet = buildAutoencoder(inputSize, 2**latentSize)\n","    model = modelSet['model']\n","    encoder = modelSet['encoder']\n","    model.compile(optimizer='adam', loss='categorical_crossentropy')\n","    model.fit(mpe_x_train, mpe_x_train, epochs=5, callbacks=[earlyStopping], verbose=0)\n","    transformed = encoder.predict(mpe_x_train)\n","    tsne_ = TSNE(n_components=2).fit_transform(transformed)\n","    \n","    plt.figure(figsize=(10, 10), dpi=400)\n","    plt.scatter(tsne_[:,0], tsne_[:,1], c=mpe_y_train)\n","    plt.show()\n","    plt.close()"],"metadata":{"id":"tUtJmyt_K2Mt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"sVmn2pgyK2Mt"}},{"cell_type":"markdown","source":["## Autoencoders for Pretraining[[](http://)](http://)"],"metadata":{"id":"_g5BRu7ZK2Mt"}},{"cell_type":"markdown","source":["Pretraining with the MNIST dataset."],"metadata":{"id":"S1YpHRT5ZROt"}},{"cell_type":"code","source":["(x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(len(x_train),784)/255\n","x_valid = x_valid.reshape(len(x_valid),784)/255"],"metadata":{"id":"b1s6aJKEZQ2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelSet = buildAutoencoder(784, 32)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","model.compile(optimizer='adam', loss='binary_crossentropy')\n","model.fit(x_train, x_train, epochs=20)"],"metadata":{"id":"IGThe6x0K2Mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp = L.Input((784,))\n","encoded = encoder(inp)\n","dense1 = L.Dense(16, activation='relu')(encoded)\n","dense2 = L.Dense(16, activation='relu')(dense1)\n","dense3 = L.Dense(10, activation='softmax')(dense2)\n","encoded.trainable = False\n","task_model = Model(inputs=inp, outputs=dense3)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n","history = model.fit(x_train, y_train, epochs=20)"],"metadata":{"id":"QbWTchnTK2Mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelSet = buildAutoencoder(784, 32)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","\n","inp = L.Input((784,))\n","encoded = encoder(inp)\n","dense1 = L.Dense(16, activation='relu')(encoded)\n","dense2 = L.Dense(16, activation='relu')(dense1)\n","dense3 = L.Dense(10, activation='softmax')(dense2)\n","encoded.trainable = False\n","task_model = Model(inputs=inp, outputs=dense3)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n","history2 = model.fit(x_train, y_train, epochs=20)\n","plt.figure(figsize=(15, 7.5), dpi=400)\n","plt.plot(history.history['loss'], color='red', label='With AE Pretraining')\n","plt.plot(history2.history['loss'], color='blue', label='Without AE Pretraining')\n","plt.grid()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"E9E3oCt5K2Mu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pretraining with the Higgs Boson dataset."],"metadata":{"id":"iLbVDXw6ZTt5"}},{"cell_type":"code","source":["train_df = pd.read_csv('../input/higs-bonsons-and-background-process/train.csv').replace('?', np.nan).dropna()\n","X_train = train_df.drop(['class', 'id'], axis=1).astype(np.float32)\n","y_train = train_df['class'].astype(np.float32)\n","\n","valid_df = pd.read_csv('../input/higs-bonsons-and-background-process/test.csv').replace('?', np.nan).dropna()\n","X_valid = valid_df.drop(['class', 'id'], axis=1).astype(np.float32)\n","y_valid = valid_df['class'].astype(np.float32)\n","encoder = Sequential()\n","encoder.add(L.Input((len(X_train.columns),)))\n","encoder.add(L.Dense(28, activation='relu'))\n","encoder.add(L.Dense(28, activation='relu'))\n","encoder.add(L.Dense(28, activation='relu'))\n","encoder.add(L.Dense(16, activation='relu'))\n","encoder.add(L.Dense(16, activation='relu'))\n","encoder.add(L.Dense(16, activation='relu'))\n","\n","decoder = Sequential()\n","decoder.add(L.Input((16,)))\n","decoder.add(L.Dense(16, activation='relu'))\n","decoder.add(L.Dense(16, activation='relu'))\n","decoder.add(L.Dense(16, activation='relu'))\n","decoder.add(L.Dense(28, activation='relu'))\n","decoder.add(L.Dense(28, activation='relu'))\n","decoder.add(L.Dense(28, activation='linear'))\n","\n","inp = L.Input((28,))\n","encoded = encoder(inp)\n","decoded = decoder(encoded)\n","ae = keras.models.Model(inputs=inp, outputs=decoded)\n","\n","ae.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","history = ae.fit(X_train, X_train, epochs=100,\n","                 validation_data=(X_valid, X_valid))\n","inp = L.Input((len(X_train.columns),))\n","encoded = encoder(inp)\n","dense1 = L.Dense(16, activation='relu')(encoded)\n","dense2 = L.Dense(16, activation='relu')(dense1)\n","dense3 = L.Dense(16, activation='relu')(dense2)\n","dense4 = L.Dense(1, activation='sigmoid')(dense3)\n","encoded.trainable = False\n","task_model = keras.models.Model(inputs=inp, outputs=dense4)\n","task_model.compile(optimizer='adam', loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","history_i = task_model.fit(X_train, y_train, epochs=70,\n","                           validation_data=(X_valid, y_valid))\n","\n","encoded.trainable = True\n","history_ii = task_model.fit(X_train, y_train, epochs=30,\n","                            validation_data=(X_valid, y_valid))\n","plt.figure(figsize=(15, 7.5), dpi=400)\n","plt.plot(range(1, 71),\n","         history_i.history['loss'], \n","         color='red', \n","         label='Train Stage I')\n","plt.plot(range(71, 101),\n","         history_ii.history['loss'], \n","         color='red',\n","         linestyle='--',\n","         label='Train Stage II')\n","plt.plot(range(1, 71),\n","         history_i.history['val_loss'], \n","         color='blue', \n","         label='Validation Stage I')\n","plt.plot(range(71, 101),\n","         history_ii.history['val_loss'], \n","         color='blue', \n","         linestyle='--',\n","         label='Validation Stage II')\n","plt.grid()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","\n","plt.figure(figsize=(15, 7.5), dpi=400)\n","plt.plot(range(1, 71),\n","         history_i.history['accuracy'], \n","         color='red', \n","         label='Train Stage I')\n","plt.plot(range(71, 101),\n","         history_ii.history['accuracy'], \n","         color='red',\n","         linestyle='--',\n","         label='Train Stage II')\n","plt.plot(range(1, 71),\n","         history_i.history['val_accuracy'], \n","         color='blue', \n","         label='Validation Stage I')\n","plt.plot(range(71, 101),\n","         history_ii.history['val_accuracy'], \n","         color='blue', \n","         linestyle='--',\n","         label='Validation Stage II')\n","plt.grid()\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"UbmHLbQRK2Mu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Multitask Autoencoders"],"metadata":{"id":"2gimoahnK2Mu"}},{"cell_type":"markdown","source":["Loading MNIST data."],"metadata":{"id":"bcM0sOa6Zl2S"}},{"cell_type":"code","source":["(x_train, y_train), (x_valid, y_valid) = tensorflow.keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(len(x_train),784)/255\n","x_valid = x_valid.reshape(len(x_valid),784)/255"],"metadata":{"id":"IcUfeuDOK2Mu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apply multitask autoencoding to MNIST."],"metadata":{"id":"olNAYGR8ax74"}},{"cell_type":"code","source":["modelSet = buildAutoencoder(784, 32)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","decoder = modelSet['decoder']\n","\n","tasker = keras.models.Sequential(name='taskOut')\n","tasker.add(L.Input((32,)))\n","for i in range(3):\n","    tasker.add(L.Dense(16, activation='relu'))\n","tasker.add(L.Dense(10, activation='softmax'))\n","\n","inp = L.Input((784,), name='input')\n","encoded = encoder(inp)\n","decoded = decoder(encoded)\n","taskOut = tasker(encoded)\n","\n","taskModel = Model(inputs=inp, outputs=[decoded, taskOut])"],"metadata":{"id":"-HcfY6YEK2Mv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensorflow.keras.utils.plot_model(taskModel, show_shapes=True)"],"metadata":{"id":"XHqP69n0K2Mw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["taskModel.compile(optimizer='adam',\n","                  loss = {'decoder':'binary_crossentropy',\n","                          'taskOut':'sparse_categorical_crossentropy'})\n","\n","TOTAL_EPOCHS = 100\n","\n","for epoch in range(1, TOTAL_EPOCHS):\n","    \n","    predictions = taskModel.predict(x_valid[0:1])\n","    \n","    plt.figure(figsize=(15, 7.5), dpi=400)\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(x_valid[0].reshape((28, 28)), cmap='gray')\n","    plt.axis('off')\n","    plt.ylabel(f'EPOCH {epoch}')\n","    plt.title('Original Input')\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(predictions[0].reshape((28, 28)), cmap='gray')\n","    plt.axis('off')\n","    plt.title('Decoder Output')\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(predictions[1].reshape((10, 1)), cmap='gray')\n","    plt.title('Task Output')\n","    plt.show()\n","    \n","    history = taskModel.fit(x_train, {'decoder':x_train, 'taskOut': y_train},\n","                            epochs=1)\n"],"metadata":{"id":"xKDmhWDBK2Mw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying multi-task autoencoding to the Mouse Protein Expression dataset."],"metadata":{"id":"bEsX67w7aBZr"}},{"cell_type":"code","source":["df = pd.read_csv('../input/mpempe/mouse-protein-expression.csv').drop('Unnamed: 0', axis=1)\n","\n","from sklearn.model_selection import train_test_split as tts\n","mpe_x = df.drop('class', axis=1)\n","mpe_y = df['class']\n","X_train, X_valid, y_train, y_valid = tts(mpe_x, mpe_y, train_size = 0.8, random_state = 42)\n","from keras.models import Sequential\n","\n","encoder = Sequential()\n","encoder.add(L.Input((len(X_train.columns),)))\n","encoder.add(L.Dense(28, activation='relu'))\n","encoder.add(L.Dense(28, activation='relu'))\n","encoder.add(L.Dense(28, activation='relu'))\n","encoder.add(L.Dense(16, activation='relu'))\n","encoder.add(L.Dense(16, activation='relu'))\n","encoder.add(L.Dense(16, activation='relu'))\n","\n","decoder = Sequential(name='decoder')\n","decoder.add(L.Input((16,)))\n","decoder.add(L.Dense(16, activation='relu'))\n","decoder.add(L.Dense(16, activation='relu'))\n","decoder.add(L.Dense(16, activation='relu'))\n","decoder.add(L.Dense(28, activation='relu'))\n","decoder.add(L.Dense(28, activation='relu'))\n","decoder.add(L.Dense(len(X_train.columns), activation='linear'))\n","\n","modelSet = buildAutoencoder(len(X_train.columns), 32, outActivation='linear')\n","ae = modelSet['model']\n","encoder = modelSet['encoder']\n","decoder = modelSet['decoder']\n","\n","inp = L.Input((len(X_train.columns),))\n","encoded = encoder(inp)\n","decoded = decoder(encoded)\n","ae = keras.models.Model(inputs=inp, outputs=decoded)\n","\n","ae.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","history = ae.fit(X_train, X_train, epochs=100,\n","                 validation_data=(X_valid, X_valid))\n","\n","\n","from keras.models import Model\n","\n","tasker = keras.models.Sequential(name='taskOut')\n","tasker.add(L.Input((32,)))\n","for i in range(3):\n","    tasker.add(L.Dense(16, activation='relu'))\n","tasker.add(L.Dense(8, activation='softmax'))\n","\n","inp = L.Input((len(X_train.columns),), name='input')\n","encoded = encoder(inp)\n","decoded = decoder(encoded)\n","taskOut = tasker(encoded)\n","\n","taskModel = Model(inputs=inp, outputs=[decoded, taskOut])\n","tensorflow.keras.utils.plot_model(taskModel, show_shapes=True)\n","taskModel.compile(optimizer='adam',\n","                  loss = {'decoder':'mse',\n","                          'taskOut':'sparse_categorical_crossentropy'})\n","\n","TOTAL_EPOCHS = 5\n","\n","X_valid = np.array(X_valid)\n","y_valid = np.array(y_valid)\n","\n","for epoch in range(1, TOTAL_EPOCHS):\n","    \n","    # show performance on three samples\n","    for index in range(3):\n","        print('-'*50)\n","        print(f'Epoch {epoch}')\n","\n","        predictions = taskModel.predict(X_valid[index:index+1])\n","\n","        plt.figure(figsize=(30/4*3, 6), dpi=400)\n","        plt.subplot(1, 3, 1)\n","        sns.heatmap(X_valid[index].reshape((8, 10)),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5)\n","        plt.axis('off')\n","        plt.ylabel(f'EPOCH {epoch}')\n","        plt.title('Original Input')\n","        plt.subplot(1, 3, 2)\n","        sns.heatmap(predictions[0].reshape((8, 10)),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5)\n","        plt.axis('off')\n","        plt.title('Decoder Output')\n","        plt.subplot(1, 3, 3)\n","        sns.heatmap(np.abs(predictions[0].reshape((8, 10)) - X_valid[index].reshape((8, 10))),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5)\n","        plt.axis('off')\n","        plt.title('Recon. Abs. Error')\n","        plt.show()\n","        \n","        plt.close()\n","        \n","        plt.figure(figsize=(10, 4), dpi=400)\n","        plt.subplot(3, 1, 1)\n","        sns.heatmap(predictions[1][0].reshape((1, 8)),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5,\n","                    yticklabels=['Predicted'],\n","                    xticklabels=['' for i in range(8)])\n","        plt.subplot(3, 1, 2)\n","        mat = np.zeros((8, 1))\n","        mat[int(y_valid[index]) - 1] = 1\n","        sns.heatmap(mat.reshape((1, 8)),\n","                    annot=True,\n","                    fmt='.3f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5,\n","                    yticklabels=['Truth'],\n","                    xticklabels=['' for i in range(8)])\n","        plt.subplot(3, 1, 3)\n","        sns.heatmap(np.abs(predictions[1][0].reshape((1, 8)) - mat.reshape((1, 8))),\n","                    annot=True,\n","                    fmt='.3f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5,\n","                    yticklabels=['Abs. Error'])\n","        plt.show()\n","        plt.close()\n","    \n","    # fit for one epoch\n","    taskModel.fit(X_train, {'decoder':X_train, 'taskOut': y_train - 1},\n","                  epochs=1)"],"metadata":{"id":"NzeBeUtKaADj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelSet = buildAutoencoder(784, 32)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","decoder = modelSet['decoder']\n","\n","tasker = keras.models.Sequential(name='taskOut')\n","tasker.add(L.Input((32,)))\n","for i in range(3):\n","    tasker.add(L.Dense(16, activation='relu'))\n","tasker.add(L.Dense(10, activation='softmax'))\n","\n","inp = L.Input((784,), name='input')\n","encoded = encoder(inp)\n","decoded = decoder(encoded)\n","taskOut = tasker(encoded)\n","\n","taskModel = Model(inputs=inp, outputs=[decoded, taskOut])\n","plt.figure(figsize=(15, 7.5), dpi=400)\n","epochs = np.linspace(1, 100, 100)\n","alpha = (1/(1 + np.exp(-(epochs-50)/10))) / 2 + (1/4)\n","plt.plot(epochs, alpha, color='red', label='Task Output Weight')\n","plt.plot(epochs, 1-alpha, color='blue', label='Decoder Output Weight')\n","plt.xlabel('Epochs')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()\n","ae.compile(optimizer='adam',\n","           loss='mae')\n","ae.fit(X_train, X_train, epochs=1) # change this!\n","total_epochs = 1 # change this!\n","\n","lossParams = {'decoder':'mse',\n","              'taskOut':'sparse_categorical_crossentropy'}\n","\n","loss, decoderLoss, taskOutLoss = [], [], []\n","\n","for epoch in range(1, total_epochs+1):\n","    \n","    alpha = (1/(1 + np.exp(-(epoch-50)/5)))\n","    \n","    for index in range(3):\n","    \n","        print('-'*500)\n","        print(f'Epoch {epoch}')\n","\n","        predictions = taskModel.predict(X_valid[index:index+1])\n","\n","        plt.figure(figsize=(30/4*3, 6), dpi=400)\n","        plt.subplot(1, 3, 1)\n","        sns.heatmap(X_valid[index].reshape((8, 10)),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5)\n","        plt.axis('off')\n","        plt.ylabel(f'EPOCH {epoch}')\n","        plt.title('Original Input')\n","        plt.subplot(1, 3, 2)\n","        sns.heatmap(predictions[0].reshape((8, 10)),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5)\n","        plt.axis('off')\n","        plt.title('Decoder Output')\n","        plt.subplot(1, 3, 3)\n","        sns.heatmap(np.abs(predictions[0].reshape((8, 10)) - X_valid[index].reshape((8, 10))),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5)\n","        plt.axis('off')\n","        plt.title('Recon. Abs. Error')\n","        plt.show()\n","        \n","        plt.close()\n","        \n","        plt.figure(figsize=(10, 4), dpi=400)\n","        plt.subplot(3, 1, 1)\n","        sns.heatmap(predictions[1][0].reshape((1, 8)),\n","                    annot=True,\n","                    fmt='.1f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5,\n","                    yticklabels=['Predicted'],\n","                    xticklabels=['' for i in range(8)])\n","        plt.subplot(3, 1, 2)\n","        mat = np.zeros((8, 1))\n","        mat[int(y_valid[index])] = 1\n","        sns.heatmap(mat.reshape((1, 8)),\n","                    annot=True,\n","                    fmt='.3f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5,\n","                    yticklabels=['Truth'],\n","                    xticklabels=['' for i in range(8)])\n","        plt.subplot(3, 1, 3)\n","        sns.heatmap(np.abs(predictions[1][0].reshape((1, 8)) - mat.reshape((1, 8))),\n","                    annot=True,\n","                    fmt='.3f',\n","                    cmap='gray',\n","                    cbar=False,\n","                    vmin = -1.5,\n","                    vmax = 2.5,\n","                    yticklabels=['Abs. Error'])\n","        plt.show()\n","        plt.close()\n","    \n","    \n","    taskModel.compile(optimizer='adam',\n","                      loss = lossParams,\n","                      loss_weights = {'taskOut': alpha,\n","                                      'decoder': 1-alpha},\n","                      metrics = {'taskOut': ['accuracy']})\n","    history = taskModel.fit(X_train, {'decoder':X_train, 'taskOut': y_train - 1},\n","                            epochs = 1, batch_size = 128)\n","    loss.extend(history.history['loss'])\n","    decoderLoss.extend(history.history['decoder_loss'])\n","    taskOutLoss.extend(history.history['taskOut_loss'])"],"metadata":{"id":"LcG_e-JuK2Mw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15, 7.5), dpi=400)\n","plt.plot(range(1, total_epochs+1), decoderLoss, color='red', linestyle='--', label='Reconstruction Loss')\n","plt.plot(range(1, total_epochs+1), taskOutLoss, color='blue', label='Task Loss')\n","plt.plot(range(1, total_epochs+1), loss, color='green', linestyle='-.', label='Overall Loss')\n","\n","for i in np.linspace(1, 100, 500):\n","    plt.axvline(x=i, linestyle='-', linewidth=0.5, color='blue', alpha=1/(1 + np.exp(-(i-50)/7.5)))\n","for i in np.linspace(1, 100, 500):\n","    plt.axvline(x=i, linestyle='-', linewidth=0.5, color='red', alpha=1-1/(1 + np.exp(-(i-50)/7.5)))\n","    \n","plt.grid()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"fsZ-Crg5K2Mx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"YgZSx5RxK2Mx"}},{"cell_type":"markdown","source":["## Sparse Autoencoders"],"metadata":{"id":"LWmqz2-rK2Mx"}},{"cell_type":"markdown","source":["Modifying the autoencoder function as a sparse autoencoder function."],"metadata":{"id":"F8ur4kZrambI"}},{"cell_type":"code","source":["from keras.models import Sequential, Model\n","import keras.layers as L\n","\n","def buildSparseAutoencoder(inputSize=784, \n","                           impLatentSize=32,\n","                           realLatentSize=128,\n","                           outActivation='sigmoid'):\n","\n","    # define architecture components\n","    encoder = Sequential(name='encoder')\n","    encoder.add(L.Input((inputSize,)))\n","    for i in range(int(np.floor(np.log2(inputSize/impLatentSize))), -1, -1):\n","        encoder.add(L.Dense(impLatentSize * 2**i, activation='relu'))\n","        encoder.add(L.Dense(impLatentSize * 2**i, activation='relu'))\n","    encoder.add(L.Dense(realLatentSize, activation='relu',\n","                        activity_regularizer = keras.regularizers.L1(0.001)))\n","    \n","    decoder = Sequential(name='decoder')\n","    decoder.add(L.Input((realLatentSize,)))\n","    for i in range(1,int(np.floor(np.log2(inputSize/impLatentSize)))+1):\n","        decoder.add(L.Dense(impLatentSize * 2**i, activation='relu'))\n","        decoder.add(L.Dense(impLatentSize * 2**i, activation='relu'))\n","    decoder.add(L.Dense(inputSize, activation=outActivation))\n","\n","    # define model archtitecture from components\n","    ae_input = L.Input((inputSize,), name='input')\n","    ae_encoder = encoder(ae_input)\n","    ae_decoder = decoder(ae_encoder)\n","    ae = Model(inputs = ae_input,\n","               outputs = ae_decoder)\n","\n","    return {'model': ae, 'encoder': encoder, 'decoder': decoder}"],"metadata":{"id":"AuGrrZFoK2Mx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying sparse autoencoders to the Higgs Boson dataset."],"metadata":{"id":"nxrLKJ32aNmA"}},{"cell_type":"code","source":["train_df = pd.read_csv('../input/higs-bonsons-and-background-process/train.csv').replace('?', np.nan).dropna()\n","X_train = train_df.drop(['class', 'id'], axis=1).astype(np.float32)\n","y_train = train_df['class'].astype(np.float32)\n","\n","valid_df = pd.read_csv('../input/higs-bonsons-and-background-process/test.csv').replace('?', np.nan).dropna()\n","X_valid = valid_df.drop(['class', 'id'], axis=1).astype(np.float32)\n","y_valid = valid_df['class'].astype(np.float32)\n","modelSet = buildSparseAutoencoder(28, 8, 64, 'linear')\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","model.compile(optimizer='adam', loss='mse')\n","history = model.fit(X_train, X_train, epochs=1, # change this!\n","                    verbose=1,\n","                    validation_data=(X_valid, X_valid)"],"metadata":{"id":"f7TRQvelK2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","X_train = np.array(X_train)\n","\n","encoded = encoder.predict(X_train)\n","reconst = model.predict(X_train)\n","\n","plt.set_cmap('gray')\n","\n","for i in range(5):\n","\n","    plt.figure(figsize=(15, 5), dpi=400)\n","    plt.subplot(1, 3, 1)\n","    plt.title('Original Image')\n","    plt.axis('off')\n","    plt.imshow(X_train[i].reshape((7, 4)))\n","    plt.subplot(1, 3, 2)\n","    plt.title('Latent Space')\n","    plt.axis('off')\n","    plt.imshow(encoded[i].reshape((8, 8)))\n","    plt.subplot(1, 3, 3)\n","    plt.title('Reconstructed Image')\n","    plt.axis('off')\n","    plt.imshow(reconst[i].reshape((7, 4)))\n","    plt.show()"],"metadata":{"id":"7f1QWm8eK2My"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying sparse autoencoders to the Mouse Protein Expression dataset."],"metadata":{"id":"ip8nJa4PaSJz"}},{"cell_type":"code","source":["df = pd.read_csv('../input/mpempe/mouse-protein-expression.csv').drop('Unnamed: 0', axis=1)\n","\n","from sklearn.model_selection import train_test_split as tts\n","mpe_x = df.drop('class', axis=1)\n","mpe_y = df['class']\n","X_train, X_valid, y_train, y_valid = tts(mpe_x, mpe_y, train_size = 0.8, random_state = 42)"],"metadata":{"id":"p7aDtCsIK2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelSet = buildSparseAutoencoder(80, 16, 64, 'linear')\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","model.compile(optimizer='adam', loss='mse')\n","history = model.fit(X_train, X_train, epochs=100, verbose=1,\n","                    validation_data=(X_valid, X_valid))"],"metadata":{"id":"gGyKA4zGK2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","X_train = np.array(X_train)\n","\n","encoded = encoder.predict(X_train)\n","reconst = model.predict(X_train)\n","\n","plt.set_cmap('gray')\n","\n","for i in range(5):\n","\n","    plt.figure(figsize=(15, 5), dpi=400)\n","    plt.subplot(1, 3, 1)\n","    plt.title('Original Image')\n","    plt.axis('off')\n","    plt.imshow(X_train[i].reshape((8, 10)))\n","    plt.subplot(1, 3, 2)\n","    plt.title('Latent Space')\n","    plt.axis('off')\n","    plt.imshow(encoded[i].reshape((8, 8)))\n","    plt.subplot(1, 3, 3)\n","    plt.title('Reconstructed Image')\n","    plt.axis('off')\n","    plt.imshow(reconst[i].reshape((8, 10)))\n","    plt.show()"],"metadata":{"id":"cPVe2pq3K2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_valid, y_valid) = tensorflow.keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(len(x_train),784)/255\n","x_valid = x_valid.reshape(len(x_valid),784)/255"],"metadata":{"id":"DSfnsKIvK2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelSet = buildSparseAutoencoder(784, 64, 256)\n","model = modelSet['model']\n","encoder = modelSet['encoder']\n","model.compile(optimizer='adam', loss='binary_crossentropy')\n","history = model.fit(x_train, x_train, epochs=50, verbose=1)"],"metadata":{"id":"dsqnSP5BK2My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","encoded = encoder.predict(x_train)\n","reconst = model.predict(x_train)\n","\n","plt.set_cmap('gray')\n","\n","for i in range(5):\n","\n","    plt.figure(figsize=(15, 5), dpi=400)\n","    plt.subplot(1, 3, 1)\n","    plt.title('Original Image')\n","    plt.axis('off')\n","    plt.imshow(x_train[i].reshape((28, 28)))\n","    plt.subplot(1, 3, 2)\n","    plt.title('Latent Space')\n","    plt.axis('off')\n","    plt.imshow(encoded[i].reshape((16, 16)))\n","    plt.subplot(1, 3, 3)\n","    plt.title('Reconstructed Image')\n","    plt.axis('off')\n","    plt.imshow(reconst[i].reshape((28, 28)))\n","    plt.show()\n","    \n","    print('-'*50)"],"metadata":{"id":"jWGuX-cnK2Mz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"Pou2pXmhK2Mz"}},{"cell_type":"markdown","source":["## Denoising Autoencoders"],"metadata":{"id":"ZhWHUTXTK2Mz"}},{"cell_type":"markdown","source":["Applying denoising autoencoders to the MNIST dataset."],"metadata":{"id":"cpE4p8tkagVQ"}},{"cell_type":"code","source":["(x_train, y_train), (x_valid, y_valid) = tensorflow.keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(len(x_train),784)/255\n","x_valid = x_valid.reshape(len(x_valid),784)/255"],"metadata":{"id":"40aeApp4af7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for std in [0, 0.1, 0.2, 0.3, 0.5, 0.9]:\n","\n","    modified = x_train + np.random.normal(0, std, size=x_train.shape)\n","    modified_clipped = np.clip(modified, 0, 1)\n","\n","    plt.set_cmap('gray')\n","    plt.figure(figsize=(20, 20), dpi=400)\n","    for i in range(25):\n","        plt.subplot(5, 5, i+1)\n","        plt.imshow(modified_clipped[i].reshape((28, 28)))\n","        plt.axis('off')\n","    plt.title(f'STD: {std}')\n","    plt.show()"],"metadata":{"id":"nUWrFy7_K2Mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = buildAutoencoder(784, 32)\n","model = models['model']\n","encoder = models['encoder']\n","\n","model.compile(optimizer='adam', loss='mse')"],"metadata":{"id":"CdzYErobK2Mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["std = 0.9\n","\n","TOTAL_EPOCHS = 100\n","loss = []\n","for i in tqdm(range(TOTAL_EPOCHS)):\n","    modified = x_train + np.random.normal(0, std, size=x_train.shape)\n","    modified_clipped = np.clip(modified, 0, 1)\n","    history = model.fit(modified_clipped, x_train, epochs=1, verbose=0)\n","    loss.append(history.history['loss'])\n","\n","modified = x_valid + np.random.normal(0, std, size=x_valid.shape)\n","modified_clipped = np.clip(modified, 0, 1)\n","\n","from sklearn.metrics import mean_absolute_error as mae\n","mae(model.predict(modified_clipped), x_valid)\n","\n","plt.set_cmap('gray')\n","\n","for i in range(5):\n","    \n","    plt.figure(figsize=(15, 5), dpi=400)\n","    \n","    plt.subplot(1, 3, 1)\n","    plt.imshow(modified_clipped[i].reshape((28, 28)))\n","    plt.axis('off')\n","    plt.title('Noisy Input')\n","    \n","    plt.subplot(1, 3, 2)\n","    plt.imshow(x_valid[i].reshape((28, 28)))\n","    plt.axis('off')\n","    plt.title('True Denoised')\n","    \n","    plt.subplot(1, 3, 3)\n","    plt.imshow(model.predict(x_valid[i:i+1]).reshape((28, 28)))\n","    plt.axis('off')\n","    plt.title('Predicted Denoised')\n","    \n","    plt.show()"],"metadata":{"id":"NVkioGr5K2Mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modified = x_train + np.random.normal(0, std, size=x_train.shape)\n","modified_clipped = np.clip(modified, 0, 1)\n","\n","plt.set_cmap('gray')\n","plt.figure(figsize=(20, 20), dpi=400)\n","for i in range(25):\n","    plt.subplot(5, 5, i+1)\n","    plt.imshow(modified_clipped[i].reshape((28, 28)))\n","    plt.axis('off')\n","plt.show()"],"metadata":{"id":"ae3ttm3WK2Mz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying denoising autoencoders to the Mouse Protein Expression dataset."],"metadata":{"id":"limXYrv5aYaN"}},{"cell_type":"code","source":["data = pd.read_csv('../input/mpempe/mouse-protein-expression.csv').drop(['Unnamed: 0', 'class'], axis=1)\n","train_indices = np.random.choice(data.index, replace=False, size = round(0.8 * len(data)))\n","valid_indices = np.array([ind for ind in data.index if ind not in train_indices])\n","x_train, x_valid = data.loc[train_indices], data.loc[valid_indices]\n","models = buildAutoencoder(len(data.columns), 16)\n","model = models['model']\n","encoder = models['encoder']\n","\n","model.compile(optimizer='adam', loss='mse')\n","TOTAL_EPOCHS = 100\n","loss = []\n","stds = x_train.std()\n","for i in tqdm(range(TOTAL_EPOCHS)):\n","    noise = pd.DataFrame(index=x_train.index, columns=x_train.columns)\n","    for col in noise.columns:\n","        noise[col] = np.random.normal(0, stds[col]/5, \n","                                      size=(len(x_train),))\n","    history = model.fit(x_train + noise, x_train, epochs=1, verbose=0)\n","    loss.append(history.history['loss'])\n","noise = pd.DataFrame(index=x_valid.index, columns=x_valid.columns)\n","for col in noise.columns:\n","    noise[col] = np.random.normal(0, np.sqrt(stds[col]), \n","                                  size=(len(x_valid),))\n","\n","from sklearn.metrics import mean_absolute_error as mae\n","mae(model.predict(x_valid + noise), x_valid)"],"metadata":{"id":"tnUiyDObK2M0"},"execution_count":null,"outputs":[]}]}